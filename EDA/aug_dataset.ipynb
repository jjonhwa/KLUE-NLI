{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github Clone\n",
    "!git clone https://github.com/jjonhwa/KLUE-NLI.git\n",
    "\n",
    "# Dataset Unzip\n",
    "!tar -zxvf /content/KLUE-NLI/data/klue-nli-v1.1.tar.gz\n",
    "!unzip -q /content/KLUE-NLI/data/open.zip -d /content/data\n",
    "\n",
    "# Transformer Library Download\n",
    "!pip install transformers\n",
    "\n",
    "# Kor NLI github clone\n",
    "!git clone https://github.com/kakaobrain/KorNLUDatasets.git\n",
    "\n",
    "# Original Dataset Unzip\n",
    "!unzip -q '/content/KLUE-NLI/data/open.zip' -d '/content/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "%cd KLUE-NLI\n",
    "from utils.mk_data import read_json, create_pandas\n",
    "from utils.nlpdata_eda import corpus_statistic_with_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KLUE OFFICIAL DATASET 추가 (Only Dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Path 지정\n",
    "data_dir = \"./klue-nli-v1.1\"\n",
    "valid_filename = \"klue-nli-v1.1_dev.json\"\n",
    "valid_file_path = os.path.join(data_dir, valid_filename)\n",
    "\n",
    "# Dataset 만들기\n",
    "valid_json = read_json(valid_file_path)\n",
    "valid_df = create_pandas(valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.drop(['guid', 'source'], axis = 1, inplace = True)\n",
    "valid_df.to_csv('/content/KLUE-NLI/data/klue_dev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kor NLI DATASET 추가 (with Token Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human Translated Dataset만 활용\n",
    "kakao_dev = pd.read_csv('/content/KorNLUDatasets/KorNLI/xnli.dev.ko.tsv', sep='\\t')\n",
    "kakao_test = pd.read_csv('/content/KorNLUDatasets/KorNLI/xnli.test.ko.tsv', sep='\\t')\n",
    "\n",
    "kakao_dataset = pd.concat([kakao_dev, kakao_test])\n",
    "kakao_dataset.reset_index(drop = True, inplace = True)\n",
    "kakao_dataset.columns = ['premise', 'hypothesis', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 분포 파악\n",
    "feature = kakao_dataset['label']\n",
    "\n",
    "plt.figure(figsize=(10,7.5))\n",
    "plt.title('Label Count', fontsize=20)\n",
    "\n",
    "temp = feature.value_counts()\n",
    "plt.bar(temp.keys(), temp.values, width=0.5, color='b', alpha=0.5)\n",
    "plt.text(-0.05, temp.values[0]+20, s=temp.values[0])\n",
    "plt.text(0.95, temp.values[1]+20, s=temp.values[1])\n",
    "plt.text(1.95, temp.values[2]+20, s=temp.values[2])\n",
    "\n",
    "plt.xticks(temp.keys(), fontsize=12) # x축 값, 폰트 크기 설정\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # 레이아웃 설정\n",
    "plt.show() # 그래프 나타내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Dataset 불러오기\n",
    "PATH = '/content/data/open'\n",
    "train = pd.read_csv(os.path.join(PATH, 'train_data.csv'), encoding = 'utf-8')\n",
    "test = pd.read_csv(os.path.join(PATH, 'test_data.csv'), encoding = 'utf-8')\n",
    "\n",
    "concat_dataset = pd.concat([train, test])\n",
    "concat_dataset.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 Dataset과의 중복 검사\n",
    "premise_cnt = 0\n",
    "hypothesis_cnt = 0\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(concat_dataset))):\n",
    "    if concat_dataset['premise'][i] in kakao_dataset['premise']:\n",
    "        premise_cnt += 1\n",
    "    if concat_dataset['hypothesis'][i] in kakao_dataset['hypothesis']:\n",
    "        hypothesis_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer Download\n",
    "MODEL_NAME = 'klue/roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 출력\n",
    "example_format = list(kakao_dataset['premise'])[0]\n",
    "print(tokenizer.tokenize(example_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kor NLI Dataset의 Token Length 분포 파악\n",
    "train_premise_eda = corpus_statistic_with_graph(list(kakao_dataset['premise']), tokenizer_type = 'wordpiece', tokenizer = tokenizer)\n",
    "print(train_premise_eda)\n",
    "train_hypothesis_eda = corpus_statistic_with_graph(list(kakao_dataset['hypothesis']), tokenizer_type = 'wordpiece', tokenizer = tokenizer)\n",
    "print(train_hypothesis_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 길이가 50보다 짧은 문장만 최종 선택\n",
    "drop_list = []\n",
    "for i in range(len(kakao_dataset)):\n",
    "    if len(tokenizer.tokenize(kakao_dataset['premise'][i])) > 50 or len(tokenizer.tokenize(kakao_dataset['hypothesis'][i])) > 50:\n",
    "        drop_list.append(i)\n",
    "\n",
    "kakao_dataset.drop(drop_list, axis = 0, inplace =True)\n",
    "kakao_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"추가 Dataset의 개수:\", len(kakao_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kakao_dataset.to_csv('/content/KLUE-NLI/data/kor_nli_valid.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
